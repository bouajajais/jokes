{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964biteab38f9cb13b45a88dfc43743c81f052",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "main_dir = \"\"\n",
    "jokes_dir = os.path.join(main_dir, \"joke-dataset\")\n",
    "jokes_path = os.path.join(jokes_dir, \"stupidstuff.json\")\n",
    "\n",
    "def load(filepath):\n",
    "    '''\n",
    "    reads filepath and returns jokes and scores\n",
    "    '''\n",
    "    jokes_data = []\n",
    "    scores_data = []\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        reddit_json = json.load(f)\n",
    "\n",
    "        for item in reddit_json:\n",
    "            jokes_data.append(item[\"body\"])\n",
    "            scores_data.append(round(item[\"rating\"]))\n",
    "\n",
    "    return jokes_data, scores_data\n",
    "\n",
    "jokes, scores = load(jokes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LIMIT DATA\n",
    "\n",
    "limit = 4000\n",
    "jokes, scores = jokes[:limit], scores[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PREPROCESS DATA\n",
    "\n",
    "def preprocess(X, lowercase=True, numbers=True, punctuation=True, whitespaces=True, stopwords=True, lemmatization=True):\n",
    "    # remove antislash+character (str -> str)\n",
    "    esc_chars = [\n",
    "        # r\"\\\\\",\n",
    "        # r\"\\a\",\n",
    "        # r\"\\\\b\",\n",
    "        # r\"\\f\",\n",
    "        # r\"\\r\",\n",
    "        r\"\\n\",\n",
    "        r\"\\t\"\n",
    "    ]\n",
    "    for esc_char in esc_chars:\n",
    "        X = [re.sub(esc_char, \" \", line) for line in X]\n",
    "    # replace \\\" with \" and \\' with ' (str -> str)\n",
    "    X = [re.sub(r\"\\'\", \"'\", line) for line in X]\n",
    "    X = [re.sub(r\"\\\"\", \"\\\"\", line) for line in X] \n",
    "\n",
    "    # lowercase (str -> str)\n",
    "    if lowercase:\n",
    "        X = [line.lower() for line in X]\n",
    "\n",
    "    # remove numbers (str -> str)\n",
    "    if numbers:\n",
    "        X = [re.sub(r'\\d+', '', line) for line in X]\n",
    "\n",
    "    # replace ‘ and ’ with ' and replace “ and ” with \" (str -> str)\n",
    "    X = [line.replace(\"’\",\"'\") for line in X]\n",
    "    X = [line.replace(\"‘\",\"'\") for line in X]\n",
    "    X = [line.replace(\"“\",\"\\\"\") for line in X]\n",
    "    X = [line.replace(\"”\",\"\\\"\") for line in X]\n",
    "\n",
    "    # replace punctuation with space except ' (str -> str)\n",
    "    string_punctuation = string.punctuation[:6] + string.punctuation[7:]\n",
    "    if punctuation:\n",
    "        X = [line.translate({ord(punctuation):' ' for punctuation in string_punctuation}) for line in X]\n",
    "\n",
    "    # remove whitespaces (str -> str)\n",
    "    if whitespaces:\n",
    "        X = [line.strip() for line in X]\n",
    "\n",
    "    # tokenization (str -> list)\n",
    "    X = [line.split(' ') for line in X]\n",
    "\n",
    "    # remove stopwords (list -> list)\n",
    "    if stopwords:\n",
    "        stopwords = set(STOPWORDS)\n",
    "        stopwords.update({})\n",
    "        X = [[word for word in line if len(word) > 2 and not word in stopwords] for line in X]\n",
    "    \n",
    "    # remove ' (list -> list)\n",
    "    X = [[word.translate({ord('\\''):None}) for word in line] for line in X]\n",
    "\n",
    "    # Lemmatization (list -> list)\n",
    "    if lemmatization:\n",
    "        X = [[WordNetLemmatizer().lemmatize(word) for word in line] for line in X]\n",
    "\n",
    "    return X\n",
    "\n",
    "jokes1 = preprocess(jokes, lowercase=True, numbers=True, punctuation=True, whitespaces=True, stopwords=True, lemmatization=True)\n",
    "jokes2 = preprocess(jokes, lowercase=False, numbers=False, punctuation=True, whitespaces=True, stopwords=True, lemmatization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAG_OF_WORDS\n",
    "\n",
    "def get_vocab(X):\n",
    "    '''\n",
    "    X: list of list of words\n",
    "\n",
    "    returns vocabulary of X\n",
    "    '''\n",
    "    vocab = set()\n",
    "    for sentence in X:\n",
    "        vocab.update(sentence)\n",
    "    vocab = list(vocab)\n",
    "    return vocab\n",
    "\n",
    "def bag_of_words(X, vocab):\n",
    "    '''\n",
    "    X: list of list of words\n",
    "\n",
    "    returns list of bag_of_words of each sentence in X\n",
    "    '''\n",
    "    length = len(vocab)\n",
    "\n",
    "    # transform each sentence into a bag of words\n",
    "    X_bag_of_words = []\n",
    "    for sentence in X:\n",
    "        sentence_bag_of_words = []\n",
    "        # one hot encoding representation of each word\n",
    "        for word in sentence:\n",
    "            word_one_hot_encoding = [0] * length\n",
    "            try:\n",
    "                word_index = vocab.index(word)\n",
    "                word_one_hot_encoding[word_index] = 1\n",
    "            except Exception:\n",
    "                pass\n",
    "            sentence_bag_of_words.append(word_one_hot_encoding)\n",
    "        \n",
    "        # bag of words representation of the sentence is\n",
    "        # the sum of one hot encoding representations of the words it contains\n",
    "            # OR\n",
    "        # [0] * len(vocab) if the sentence doesn't contain any word\n",
    "        if len(sentence_bag_of_words) == 0:\n",
    "            X_bag_of_words.append([0] * length)\n",
    "        else:\n",
    "            X_bag_of_words.append([\n",
    "                sum([word_one_hot_encoding[i] for word_one_hot_encoding in sentence_bag_of_words]) for i in range(length)\n",
    "            ])\n",
    "\n",
    "    return X_bag_of_words\n",
    "\n",
    "vocab1 = get_vocab(jokes1)\n",
    "vocab2 = get_vocab(jokes2)\n",
    "\n",
    "jokes1 = bag_of_words(jokes1, vocab1)\n",
    "jokes2 = bag_of_words(jokes2, vocab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SPLIT DATA\n",
    "\n",
    "def split(X, Y, split=0.3, random_state=109):\n",
    "    # Split dataset into training set and test set\n",
    "    # 70% training and 30% test (default)\n",
    "    return train_test_split(X, Y, test_size=split, random_state=random_state)\n",
    "\n",
    "X_train1, X_test1, Y_train1, Y_test1 = split(jokes1, scores, split=0.3)\n",
    "X_train2, X_test2, Y_train2, Y_test2 = split(jokes2, scores, split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE MODELS\n",
    "\n",
    "def cross_validation(model, X, Y, cv, scoring):\n",
    "    return cross_validate(model, X, Y, cv=cv, scoring=scoring)\n",
    "\n",
    "def get_confusion_matrices(results):\n",
    "    confusion_matrices = np.array([\n",
    "        [\n",
    "            [\n",
    "                results[f\"test_{i}{j}\"][k] for j in range(6)\n",
    "            ] for i in range(6)\n",
    "        ] for k in range(iterations)\n",
    "    ])\n",
    "    return confusion_matrices\n",
    "\n",
    "def show_results(results):\n",
    "    confusion_matrices = get_confusion_matrices(results)\n",
    "    print('confusion matrices :')\n",
    "    print(confusion_matrices)\n",
    "    print(f'accuracy = {results[\"test_accuracy\"]}')\n",
    "    print(f'recall = {results[\"test_recall\"]}')\n",
    "    print(f'precision = {results[\"test_precision\"]}')\n",
    "    print(f'f1 = {results[\"test_f1\"]}')\n",
    "    return confusion_matrices\n",
    "\n",
    "def conf_mat(y_true, y_pred, i, j):\n",
    "    return confusion_matrix(y_true, y_pred, labels=list(range(6)))[i, j]\n",
    "\n",
    "def make_score(metric):\n",
    "    return make_scorer(metric, average='macro')\n",
    "\n",
    "dec_tree1 = DecisionTreeClassifier()\n",
    "rand_forest1 = RandomForestClassifier(random_state=6)\n",
    "log_reg1 = LogisticRegression()\n",
    "dec_tree2 = DecisionTreeClassifier()\n",
    "rand_forest2 = RandomForestClassifier(random_state=6)\n",
    "log_reg2 = LogisticRegression()\n",
    "\n",
    "iterations = 3\n",
    "\n",
    "scoring = {\n",
    "    f'{i}{j}' : make_scorer(conf_mat, i=i, j=j) for i in range(6) for j in range(6)\n",
    "}\n",
    "\n",
    "scoring['accuracy'] = make_scorer(accuracy_score)\n",
    "scoring['precision'] = make_score(precision_score)\n",
    "scoring['recall'] = make_score(recall_score)\n",
    "scoring['f1'] = make_score(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrices :\n[[[ 0  0  0  0  0  0]\n  [ 0  0  0  0  0  0]\n  [ 0  0  2  2  4  0]\n  [ 0  0  4  6 10  1]\n  [ 0  1  1 11 19  2]\n  [ 0  0  2  4  1  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  0  0  1]\n  [ 0  0  1  5  2  0]\n  [ 0  0  3  9  8  1]\n  [ 0  0  1  7 21  4]\n  [ 0  0  0  4  3  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  1  0  0]\n  [ 0  0  2  3  3  0]\n  [ 0  0  1 10  8  1]\n  [ 0  0  1 13 20  0]\n  [ 0  0  1  2  4  0]]]\naccuracy = [0.38571429 0.44285714 0.45714286]\nrecall = [0.21890756 0.23798701 0.26764706]\nprecision = [0.20838306 0.23552941 0.26325123]\nf1 = [0.21336898 0.23440323 0.25911314]\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING 1\n",
    "# MODEL 1 : Decision Tree\n",
    "\n",
    "dec_tree1_results = cross_validation(dec_tree1, X_train1, Y_train1, iterations, scoring)\n",
    "dec_tree1_confusion_matrices = show_results(dec_tree1_results)\n",
    "dec_tree1 = dec_tree1.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrices :\n[[[ 0  0  0  0  0  0]\n  [ 0  0  0  0  0  0]\n  [ 0  0  0  1  7  0]\n  [ 0  0  0  1 20  0]\n  [ 0  0  0  2 32  0]\n  [ 0  0  0  0  7  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  0  1  0]\n  [ 0  0  0  0  8  0]\n  [ 0  0  0  0 21  0]\n  [ 0  0  0  1 32  0]\n  [ 0  0  0  0  7  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  0  1  0]\n  [ 0  0  0  2  6  0]\n  [ 0  0  0  2 18  0]\n  [ 0  0  0  5 29  0]\n  [ 0  0  0  2  5  0]]]\naccuracy = [0.47142857 0.45714286 0.44285714]\nrecall = [0.24719888 0.19393939 0.19058824]\nprecision = [0.18371212 0.09275362 0.13466872]\nf1 = [0.18       0.1254902  0.15053763]\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING 1\n",
    "# MODEL 2 : Random Forest\n",
    "\n",
    "rand_forest1_results = cross_validation(rand_forest1, X_train1, Y_train1, iterations, scoring)\n",
    "rand_forest1_confusion_matrices = show_results(rand_forest1_results)\n",
    "rand_forest1 = rand_forest1.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrices :\n[[[ 0  0  0  0  0  0]\n  [ 0  0  0  0  0  0]\n  [ 0  0  0  5  3  0]\n  [ 0  0  0  5 15  1]\n  [ 0  0  0  8 25  1]\n  [ 0  0  1  1  5  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  0  1  0]\n  [ 0  0  0  2  5  1]\n  [ 0  0  1  4 16  0]\n  [ 0  0  0 12 20  1]\n  [ 0  0  2  0  5  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  1  0  0]\n  [ 0  0  1  5  2  0]\n  [ 0  0  0  6 14  0]\n  [ 0  0  0 14 19  1]\n  [ 0  0  0  5  2  0]]]\naccuracy = [0.42857143 0.34285714 0.37142857]\nrecall = [0.24334734 0.15930736 0.19676471]\nprecision = [0.19599781 0.12955083 0.34141238]\nf1 = [0.21493902 0.14102564 0.19854552]\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING 1\n",
    "# MODEL 3 : Logistic Regression\n",
    "\n",
    "log_reg1_results = cross_validation(log_reg1, X_train1, Y_train1, iterations, scoring)\n",
    "log_reg1_confusion_matrices = show_results(log_reg1_results)\n",
    "log_reg1 = log_reg1.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrices :\n[[[ 0  0  0  0  0  0]\n  [ 0  0  0  0  0  0]\n  [ 0  1  0  4  2  1]\n  [ 0  0  3  9  8  1]\n  [ 0  0  2  9 19  4]\n  [ 0  0  1  3  3  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  0  1  0]\n  [ 0  0  1  5  2  0]\n  [ 0  0  2  9  6  4]\n  [ 0  0  1 11 15  6]\n  [ 0  0  0  3  4  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  1  0  0]\n  [ 0  0  2  5  1  0]\n  [ 0  0  1  9  7  3]\n  [ 0  0  1 15 14  4]\n  [ 0  0  0  2  4  1]]]\naccuracy = [0.4        0.35714286 0.37142857]\nrecall = [0.19747899 0.20162338 0.25092437]\nprecision = [0.19075    0.22142857 0.28894231]\nf1 = [0.19341238 0.20516338 0.25589744]\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING 2\n",
    "# MODEL 1 : Decision Tree\n",
    "\n",
    "dec_tree2_results = cross_validation(dec_tree2, X_train2, Y_train2, iterations, scoring)\n",
    "dec_tree2_confusion_matrices = show_results(dec_tree2_results)\n",
    "dec_tree2 = dec_tree2.fit(X_train2, Y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrices :\n[[[ 0  0  0  0  0  0]\n  [ 0  0  0  0  0  0]\n  [ 0  0  0  2  6  0]\n  [ 0  0  0  1 20  0]\n  [ 0  0  0  0 34  0]\n  [ 0  0  0  1  6  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  0  1  0]\n  [ 0  0  0  1  7  0]\n  [ 0  0  0  1 20  0]\n  [ 0  0  0  1 32  0]\n  [ 0  0  0  1  6  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  0  1  0]\n  [ 0  0  0  3  5  0]\n  [ 0  0  0  5 15  0]\n  [ 0  0  0  9 25  0]\n  [ 0  0  0  3  4  0]]]\naccuracy = [0.5        0.47142857 0.42857143]\nrecall = [0.26190476 0.2034632  0.19705882]\nprecision = [0.19128788 0.1469697  0.15      ]\nf1 = [0.19       0.14529293 0.16904762]\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING 2\n",
    "# MODEL 2 : Random Forest\n",
    "\n",
    "rand_forest2_results = cross_validation(rand_forest2, X_train2, Y_train2, iterations, scoring)\n",
    "rand_forest2_confusion_matrices = show_results(rand_forest2_results)\n",
    "rand_forest2 = rand_forest2.fit(X_train2, Y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrices :\n[[[ 0  0  0  0  0  0]\n  [ 0  0  0  0  0  0]\n  [ 0  0  0  5  3  0]\n  [ 0  0  0  4 17  0]\n  [ 0  0  0  9 24  1]\n  [ 0  0  0  3  4  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  0  1  0]\n  [ 0  0  0  3  4  1]\n  [ 0  0  0  4 17  0]\n  [ 0  0  1  9 23  0]\n  [ 0  0  1  0  6  0]]\n\n [[ 0  0  0  0  0  0]\n  [ 0  0  0  1  0  0]\n  [ 0  0  1  5  2  0]\n  [ 0  0  0  7 13  0]\n  [ 0  0  0 13 20  1]\n  [ 0  0  0  3  3  1]]]\naccuracy = [0.4        0.38571429 0.41428571]\nrecall = [0.4        0.38571429 0.41428571]\nprecision = [0.4        0.38571429 0.41428571]\nf1 = [0.4        0.38571429 0.41428571]\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING 2\n",
    "# MODEL 3 : Logistic Regression\n",
    "\n",
    "log_reg2_results = cross_validation(log_reg2, X_train2, Y_train2, iterations, scoring)\n",
    "log_reg2_confusion_matrices = show_results(log_reg2_results)\n",
    "log_reg2 = log_reg2.fit(X_train2, Y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "decision tree :  4\ndecision tree :  4\nrandom forest :  4\nrandom forest :  4\nlogistic regression :  4\nlogistic regression :  3\n"
     ]
    }
   ],
   "source": [
    "# ENTER YOUR JOKE TO TEST IT ON THE DIFFERENT MODELS\n",
    "\n",
    "JOKE = ''\n",
    "\n",
    "# EXAMPLES\n",
    "# JOKE = 'What do you call a sleeping bull? A bulldozer!'\n",
    "# JOKE = 'What has four wheels and flies? A garbage truck!'\n",
    "# # Score = 2\n",
    "# JOKE = jokes[7]\n",
    "# JOKE = jokes[42]\n",
    "# # Score = 3\n",
    "# JOKE = jokes[0]\n",
    "# JOKE = jokes[2]\n",
    "# JOKE = jokes[11]\n",
    "\n",
    "joke = preprocess([JOKE])\n",
    "jokes1 = bag_of_words(joke, vocab1)\n",
    "jokes2 = bag_of_words(joke, vocab2)\n",
    "# model 1 : decision tree\n",
    "print(\"decision tree : \", dec_tree1.predict(jokes1)[0])\n",
    "print(\"decision tree : \", dec_tree2.predict(jokes2)[0])\n",
    "# model 2 : random forest\n",
    "print(\"random forest : \", rand_forest1.predict(jokes1)[0])\n",
    "print(\"random forest : \", rand_forest2.predict(jokes2)[0])\n",
    "# model 3 : logistic regression\n",
    "print(\"logistic regression : \", log_reg1.predict(jokes1)[0])\n",
    "print(\"logistic regression : \", log_reg2.predict(jokes2)[0])"
   ]
  }
 ]
}